1. Correctness
What makes a CSV parser “correct”? We're not asking for additional input-output 
pairs here, but fairly precise, natural-language descriptions. Put another way, 
what kinds of general properties should your tests be checking about your CSV 
parser?

For example, if we were writing a program to control a robot arm in an assembly 
plant, we might write properties like:
the program never extends the arm beyond 5 feet; 
the arm always returns to its neutral rest position when the system is shut 
down; or
if sensors detect movement in the assembly area, movement immediately freezes.


A CSV parser needs to extract usable data from a CSV file in the correct format.
The user should be able to specify the expected format (by providing zod schema)
and the parser should follow that schema, report errors if any in an informative 
way, and respond to 
the errors either by stopping execution or proceeding in a way specified by 
the user. The parser should be robust. It can work with different versions of 
CSV format and corrupted or malformed files. It should also produce a clean 
return; it should group data in a user-specified structure (transforming data).
It might also feature more user-friendly features, such as printing out a 
stats message at the end of execution, search function that allows user to 
check the presence or location of some data, etc.


2. Random, On-Demand Generation
Suppose we gave you a function that randomly produced CSV data on demand. 
You could then call this class from your testing code. How might you use this 
source of random data to expand the power of your testing?

Random data generation provides better evaluation on unexpected data. I think 
the biggest advantage would be it helps to capture some missed edge cases and 
to evaluate the parser's performance on extremely large files. It also helps 
reduce bias hidden inside test-cases written by humans. But we should never 
solely rely on it to capture all edge cases and bugs.


3. Overall experience, Bugs encountered and resolved
In what ways did this sprint differ from prior programming assignments you’ve 
done? Did anything surprise you? Did you encounter any bugs during your work on 
this sprint? If yes, what were they and how did you fix them? If not, how do you
think that you managed to avoid them? 

The biggest challenge so far was thinking from an engineering perspective. The 
sprint really motivated me to think from both the developer's perspective and 
more importantly the user's perspective. This insights into product managing 
is something missing in prior CS courses I took. In terms of bugs, I haven't 
really encountered significant bugs because the features are not so complicated, 
though it's indeed challenging to code in a whole new language.